---
title: "Introduction to Dimensional Reduction in R - UseR!22 (Section II)"
author: "Isabella Bicalho Frazeto"
date: '2022-06-19'
output: html_document
---

# Section 1
In this section we will explore the dataset for PCA and ICA and define a little bit more how to to use tidymodels. 

## Importing libraries

```{r}
#import data and tidy models, section 1
library(tidymodels)
tidymodels_prefer()
library(bestNormalize)
library(cowplot)
library(ggforce)
library(forcats)
library(tidytext)
```

## Dataset

Let's inspect the dataset

```{r}

library(beans)
skimr::skim(beans)
colnames(beans)
```

Taking a closer look at area:

```{r}

beans %>%
  ggplot(aes(x = area)) +
  geom_histogram() +
  theme_minimal() +
  panel_border(color = "black")

```

Would log-scaling make a difference?

```{r}

beans %>%
  ggplot(aes(x = log(area))) +
  geom_histogram() +
  theme_minimal() +
  panel_border(color = "black")
  
```


## Tidy models

```{r}
set.seed(126)
beans_split <- initial_split(beans, prop = 0.80)
beans_train <- training(beans_split)
beans_test  <-  testing(beans_split)

```


### Recipes
A step-by-step description of how you process your data prior to the analysis


```{r}
recipe_rf <- recipe(class ~ ., data = beans_train) 

```

### What is our model? 

```{r}
rf_model <- rand_forest(
            mode = "classification",
            engine = "ranger"
            )
```

### Workflow

```{r}

rf_wk <- workflow() %>%
          add_recipe(recipe_rf) %>%
          add_model(rf_model)

```

### Fitting the workflow 

```{r}
rf_fit <- fit(rf_wk, beans_train)

```

### Where do I get my results?

```{r}
rf_predict <- predict(rf_fit, beans_test)

```


```{r}
rf_aug <- augment(rf_fit, beans_test)

```

### Metrics

```{r}
rf_aug %>% 
  recall(truth = class, estimate = .pred_class,  estimator = "macro_weighted")
```


### Our preprocessing

We have seen in the previous section that we have to some preprocessing. Here, we will:
1) remove zero_variance from the data
2) do order quantile normalizing 
3) center and scale the data (normalize)

```{r}
  
beans_preproc_rec <-   recipe(class ~ ., data = beans) %>%
                          step_zv(all_numeric_predictors()) %>%
                          step_orderNorm(all_numeric_predictors()) %>% 
                          step_normalize(all_numeric_predictors())


```

We have a recipe, we can prepare our data.

```{r}

beans_rec_prepped <- prep(beans_preproc_rec,
                          verbose = TRUE)

beans_rec_prepped
```

We can bake our recipe to get our results

```{r}
beans_processed <- bake(beans_rec_prepped,
                           new_data = NULL)
```

Recall the previous plot: 

```{r}

beans %>%
  ggplot(aes(x = area)) +
  geom_histogram() +
  theme_minimal() +
  panel_border(color = "black")

```

Let's now take a look at the area now

```{r}
beans_processed %>%
  ggplot(aes(x = area)) +
  geom_histogram() +
  theme_minimal() +
  panel_border(color = "black")
```

# Section 2

## PCA
Let's add pca recipe to our pre-processing recipe!

```{r}

beans_prepped_PCA  <- beans_rec_prepped %>%
                        step_pca(all_numeric_predictors(), num_comp = 4) %>%
                        prep() 

```

We will get the id from the recipe to get the variance. 

```{r}

step_id_PCA <- beans_prepped_PCA %>%
                  tidy() %>%
                  filter(type == 'pca') %>%
                  pull(id)

beans_variance_PCA <- tidy(beans_prepped_PCA,
                           id = step_id_PCA,
                           type = "variance")
```

Please note that there are several types of variances.

## Percent Variance
How do we now what are the the PC that matter the most?

```{r}

beans_variance_PCA %>%
  filter(terms == "percent variance") %>%
  ggplot(aes(x = component, y = value)) +
  geom_col() +
  theme_minimal_grid() +
  panel_border(color = "black")
```


## Cumulative percent variance
Altogether, how much do they explain from our variance?

```{r}

beans_variance_PCA %>%
  filter(terms == "cumulative percent variance") %>%
  ggplot(aes(x = component, y = value)) +
  geom_col() +
  theme_minimal_grid() +
  panel_border(color = "black")

```


# Let's inspect the components and their terms 
```{r}

beans_PCA_tidied <- beans_prepped_PCA %>% 
                    tidy(id = step_id_PCA)

```

How do we see how our features relate to each main component?

```{r}
beans_PCA_tidied %>%
  filter(component %in% paste0("PC", 1:3)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, nrow = 1) +
  labs(y = NULL) +
  theme_minimal_grid()
```

## Alternative way to view the same information

```{r}
beans_PCA_tidied %>%
  filter(component %in% paste0("PC", 1:3)) %>%
  mutate(
    is_positive = value > 0,
    abs_value = abs(value)
  ) %>%
  group_by(component) %>%
  slice_max(abs_value, n = 5) %>%
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, nrow = 1, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Abso val. of contribution",
    y = NULL, fill = "Is Positive?"
  ) +
  theme_minimal_grid()
  
```

## Let's bake our recipe!

```{r}

beans_baked_PCA <- bake(beans_prepped_PCA, new_data =  NULL)
beans_baked_PCA
```


```{r}
beans_baked_PCA %>% 
  ggplot(aes(x = .panel_x, y = .panel_y, color = class, fill = class)) +
  geom_point(alpha = 0.4, size = 0.5) +
  geom_autodensity(alpha = .3) +
  facet_matrix(vars(-class), layer.diag = 2) + 
  scale_color_brewer(palette = "Dark2") + 
  scale_fill_brewer(palette = "Dark2") +
  theme_minimal_grid() +
  panel_border(color = "black") +
  theme(legend.position = "bottom")


```

## Zooming in
```{r}
beans_baked_PCA %>%
  ggplot(aes(PC1, PC2, label = class)) +
  geom_point(aes(color = class), alpha = 0.7, size = 2) +
  labs(color = NULL) +
  theme_minimal_grid()
```


## ICA

We will do the same for the ICA:
  1) Create the recipe
  2) Prep the recipe
  3) Bake the recipe

```{r}
beans_rec_ICA <- beans_rec_prepped %>%
                      step_ica(all_numeric_predictors(), num_comp = 5)

beans_prepped_ICA <- beans_rec_ICA %>% prep()

beans_baked_ICA <- bake(beans_prepped_ICA, new_data = NULL)

```

## Looking at our baked results

```{r}
beans_baked_ICA %>% 
  ggplot(aes(x = .panel_x, y = .panel_y, color = class, fill = class)) +
  geom_point(alpha = 0.4, size = 0.5) +
  geom_autodensity(alpha = .3) +
  facet_matrix(vars(-class), layer.diag = 2) + 
  scale_color_brewer(palette = "Dark2") + 
  scale_fill_brewer(palette = "Dark2") +
  theme_minimal_grid() +
  panel_border(color = "black") +
  theme(legend.position = "bottom")

```


## Similarly, we can inspect the best looking one

```{r}
beans_baked_ICA %>%
  ggplot(aes(IC1, IC3, label = class)) +
  geom_point(aes(color = class), alpha = 0.7, size = 2) +
  labs(color = NULL) +
  theme_minimal_grid()
```

## Checking how much each feature contributes to each component


```{r}

step_id_ICA <- beans_prepped_ICA %>%
  tidy() %>%
  filter(type == 'ica') %>%
  pull(id)

beans_ICA_tidied <- beans_prepped_ICA %>% 
                    tidy(id = step_id_ICA)

beans_ICA_tidied %>%
  filter(component %in% paste0("IC", (1:3))) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, nrow = 1) +
  labs(y = NULL) +
  theme_minimal_grid()
```

